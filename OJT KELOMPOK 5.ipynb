{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g68rUHDtZR8U"
   },
   "source": [
    "##**1. Download Dataset**\n",
    "\n",
    "Download the ucmerced landuse dataset with 21 classes where each class has 100 images. The 21 classes are:\n",
    "\n",
    "* agricultural\n",
    "* airplane\n",
    "* baseballdiamond\n",
    "* beach\n",
    "* buildings\n",
    "* chaparral\n",
    "* denseresidential\n",
    "* forest\n",
    "* freeway\n",
    "* golf course\n",
    "* harbor\n",
    "* intersection\n",
    "* mediumresidential\n",
    "* mobilehomepark\n",
    "* overpass\n",
    "* parking lot\n",
    "* river\n",
    "* runway\n",
    "* sparseresidential\n",
    "* storage tanks\n",
    "* tennis court\n",
    "\n",
    "Where each image has a size of 256x256 RGB pixels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtwAe4nqasy0"
   },
   "source": [
    "##**2. Mountain Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DuzHrDjsZde_",
    "outputId": "f6cd5083-2ef5-4ffe-e98c-368051f6623b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXmXsvyLa1tx"
   },
   "source": [
    "##**3. Import Important Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EVnDcaYOaRRE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.io import imread, imsave\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7-OWXmra8Gc"
   },
   "source": [
    "##**4.  Extract Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5gEAEi0najfG"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  os.mkdir('data')\n",
    "except:\n",
    "  print(\"Error, there is already a 'data' folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uHBnKaCIbUvF"
   },
   "outputs": [],
   "source": [
    "data_set = os.path.join('/content/drive/MyDrive/ON_JOB_TRAINING/Images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-QqSKhobllV",
    "outputId": "c9f84e70-8552-408c-cd18-47b853ca0db5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agricultural',\n",
       " 'airplane',\n",
       " 'baseballdiamond',\n",
       " 'beach',\n",
       " 'buildings',\n",
       " 'chaparral',\n",
       " 'denseresidential',\n",
       " 'forest',\n",
       " 'freeway',\n",
       " 'golfcourse',\n",
       " 'harbor',\n",
       " 'intersection',\n",
       " 'mediumresidential',\n",
       " 'mobilehomepark',\n",
       " 'overpass',\n",
       " 'parkinglot',\n",
       " 'river',\n",
       " 'runway',\n",
       " 'sparseresidential',\n",
       " 'storagetanks',\n",
       " 'tenniscourt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = os.listdir('/content/drive/MyDrive/ON_JOB_TRAINING/Images/')\n",
    "labels.sort()\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-O6pijocyKe"
   },
   "source": [
    "##**5. Divide Dataset into Training, Validation, Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bCXianz3ctEp"
   },
   "outputs": [],
   "source": [
    "def complement (a,b):\n",
    "    f2=[]\n",
    "    for x in a:\n",
    "        x=os.path.splitext(x)[0]+'.tif'\n",
    "        if x not in b:\n",
    "            f2.append(x)\n",
    "    return (f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVgQchGbc3ZL",
    "outputId": "4293b217-3bec-41ff-b36c-907a25b72834"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: data/train/agricultural/agricultural55.png is a low contrast image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/agricultural 80\n",
      "data/validation/agricultural 10\n",
      "data/test/agricultural 10\n",
      "data/train/airplane 80\n",
      "data/validation/airplane 10\n",
      "data/test/airplane 10\n",
      "data/train/baseballdiamond 80\n",
      "data/validation/baseballdiamond 10\n",
      "data/test/baseballdiamond 10\n",
      "data/train/beach 80\n",
      "data/validation/beach 10\n",
      "data/test/beach 10\n",
      "data/train/buildings 80\n",
      "data/validation/buildings 10\n",
      "data/test/buildings 10\n",
      "data/train/chaparral 80\n",
      "data/validation/chaparral 10\n",
      "data/test/chaparral 10\n",
      "data/train/denseresidential 80\n",
      "data/validation/denseresidential 10\n",
      "data/test/denseresidential 10\n",
      "data/train/forest 80\n",
      "data/validation/forest 10\n",
      "data/test/forest 10\n",
      "data/train/freeway 80\n",
      "data/validation/freeway 10\n",
      "data/test/freeway 10\n",
      "data/train/golfcourse 80\n",
      "data/validation/golfcourse 10\n",
      "data/test/golfcourse 10\n",
      "data/train/harbor 80\n",
      "data/validation/harbor 10\n",
      "data/test/harbor 10\n",
      "data/train/intersection 80\n",
      "data/validation/intersection 10\n",
      "data/test/intersection 10\n",
      "data/train/mediumresidential 80\n",
      "data/validation/mediumresidential 10\n",
      "data/test/mediumresidential 10\n",
      "data/train/mobilehomepark 80\n",
      "data/validation/mobilehomepark 10\n",
      "data/test/mobilehomepark 10\n",
      "data/train/overpass 80\n",
      "data/validation/overpass 10\n",
      "data/test/overpass 10\n",
      "data/train/parkinglot 80\n",
      "data/validation/parkinglot 10\n",
      "data/test/parkinglot 10\n",
      "data/train/river 80\n",
      "data/validation/river 10\n",
      "data/test/river 10\n",
      "data/train/runway 80\n",
      "data/validation/runway 10\n",
      "data/test/runway 10\n",
      "data/train/sparseresidential 80\n",
      "data/validation/sparseresidential 10\n",
      "data/test/sparseresidential 10\n",
      "data/train/storagetanks 80\n",
      "data/validation/storagetanks 10\n",
      "data/test/storagetanks 10\n",
      "data/train/tenniscourt 80\n",
      "data/validation/tenniscourt 10\n",
      "data/test/tenniscourt 10\n"
     ]
    }
   ],
   "source": [
    "train_data_size=80\n",
    "validate_data_size=10\n",
    "test_data_size=10\n",
    "for j in labels:\n",
    "    path=os.path.join('/content/drive/MyDrive/ON_JOB_TRAINING/Images/',j)\n",
    "    path1_train=os.path.join('data','train',j)\n",
    "    path1_validate=os.path.join('data','validation',j)\n",
    "    path1_test=os.path.join('data','test',j)\n",
    "    \n",
    "    try:\n",
    "      shutil.rmtree(path1_train)\n",
    "      os.makedirs(path1_train)\n",
    "      shutil.rmtree(path1_validate)\n",
    "      os.makedirs(path1_validate)\n",
    "      shutil.rmtree(path1_test) \n",
    "      os.makedirs(path1_test) \n",
    "    except:\n",
    "      os.makedirs(path1_train) \n",
    "      os.makedirs(path1_validate) \n",
    "      os.makedirs(path1_test) \n",
    "    \n",
    "    \n",
    "    files1= os.listdir(path)\n",
    "    files1=files1[1:len(files1)]\n",
    "    files1= np.random.permutation(files1)\n",
    "    for i in range(0,train_data_size):\n",
    "        file=os.path.join(path,files1[i])\n",
    "        img1=imread(file)\n",
    "        n=os.path.splitext(file)\n",
    "        n=n[0].split('/')\n",
    "        n1=os.path.join(path1_train, n[-1] +'.png')\n",
    "        imsave(n1,img1)\n",
    "\n",
    "    print(path1_train, len(os.listdir(path1_train)))\n",
    "    validate_data0 = complement(files1, os.listdir(path1_train))\n",
    "    \n",
    "    validate_data = np.random.permutation(validate_data0)\n",
    "    for i in range( 0, validate_data_size):\n",
    "        file=os.path.join(path,validate_data[i])\n",
    "        img1=imread(file)\n",
    "        n=os.path.splitext(file)\n",
    "        n=n[0].split('/')\n",
    "        n1=os.path.join(path1_validate, n[-1] +'.png')\n",
    "        imsave(n1,img1)\n",
    "    print(path1_validate, len(os.listdir(path1_validate))) \n",
    "    \n",
    "    test_data0 = complement(validate_data0, os.listdir(path1_validate))\n",
    "    test_data = np.random.permutation(test_data0)\n",
    "    for i in range(0, test_data_size):\n",
    "        file=os.path.join(path,test_data[i])\n",
    "        img1=imread(file)\n",
    "        n=os.path.splitext(file)\n",
    "        n=n[0].split('/')\n",
    "        n1=os.path.join(path1_test, n[-1] +'.png')\n",
    "        imsave(n1,img1)\n",
    "        \n",
    "    print(path1_test, len(os.listdir(path1_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZUVeD5od0SS"
   },
   "source": [
    "##**6. Preprocess Image for Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66uN-zoydzxV",
    "outputId": "5a788f7f-9981-498f-ca4c-30d7ca75c537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1680 images belonging to 21 classes.\n",
      "Found 210 images belonging to 21 classes.\n",
      "Found 210 images belonging to 21 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'agricultural',\n",
       " 1: 'airplane',\n",
       " 2: 'baseballdiamond',\n",
       " 3: 'beach',\n",
       " 4: 'buildings',\n",
       " 5: 'chaparral',\n",
       " 6: 'denseresidential',\n",
       " 7: 'forest',\n",
       " 8: 'freeway',\n",
       " 9: 'golfcourse',\n",
       " 10: 'harbor',\n",
       " 11: 'intersection',\n",
       " 12: 'mediumresidential',\n",
       " 13: 'mobilehomepark',\n",
       " 14: 'overpass',\n",
       " 15: 'parkinglot',\n",
       " 16: 'river',\n",
       " 17: 'runway',\n",
       " 18: 'sparseresidential',\n",
       " 19: 'storagetanks',\n",
       " 20: 'tenniscourt'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_directory=path=os.path.join('/content/UCMerced_LandUse/Images')\n",
    "train_dir=os.path.join('data','train')\n",
    "validation_dir=os.path.join('data','validation')\n",
    "test_dir=os.path.join('data','test')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=1,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range (len(test_generator)):\n",
    "  x,y = test_generator[i]\n",
    "  X_test.append(x)\n",
    "  y_test.append(y)\n",
    "X_test = np.array(X_test).reshape(210,150,150,3)\n",
    "y_test = np.array(y_test).reshape(210,21)\n",
    "y_test_class = [np.argmax(y) for y in y_test]\n",
    "class_label = {v: k for k, v in test_generator.class_indices.items()}\n",
    "class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dO9hep4RfT0r"
   },
   "source": [
    "##**7. Build CNN Model**\n",
    "###**7.1 Train CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ja-Rm2WRfMyz",
    "outputId": "486ffa9c-0cb1-4006-8c08-3737872d4144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "53/53 [==============================] - 55s 1s/step - loss: 3.0646 - accuracy: 0.0774 - val_loss: 2.7758 - val_accuracy: 0.2000\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 53s 994ms/step - loss: 2.7866 - accuracy: 0.1524 - val_loss: 2.4716 - val_accuracy: 0.2333\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 53s 992ms/step - loss: 2.6154 - accuracy: 0.1815 - val_loss: 2.3251 - val_accuracy: 0.2571\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 53s 991ms/step - loss: 2.4884 - accuracy: 0.2131 - val_loss: 2.1371 - val_accuracy: 0.3143\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 55s 1s/step - loss: 2.4298 - accuracy: 0.2286 - val_loss: 2.2266 - val_accuracy: 0.3143\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 53s 993ms/step - loss: 2.3106 - accuracy: 0.2655 - val_loss: 2.0118 - val_accuracy: 0.3429\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.2420 - accuracy: 0.2869Epoch 8/50\n",
      "53/53 [==============================] - 53s 993ms/step - loss: 2.2153 - accuracy: 0.2821 - val_loss: 1.7958 - val_accuracy: 0.4286\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 53s 988ms/step - loss: 2.1704 - accuracy: 0.2976 - val_loss: 1.7825 - val_accuracy: 0.4810\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 53s 989ms/step - loss: 2.0588 - accuracy: 0.3226 - val_loss: 1.6733 - val_accuracy: 0.4857\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 53s 987ms/step - loss: 2.0808 - accuracy: 0.3482 - val_loss: 1.7350 - val_accuracy: 0.4571\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 53s 990ms/step - loss: 1.9938 - accuracy: 0.3643 - val_loss: 1.6476 - val_accuracy: 0.5381\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 53s 990ms/step - loss: 1.9627 - accuracy: 0.3655 - val_loss: 1.6981 - val_accuracy: 0.4810\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 53s 990ms/step - loss: 1.9475 - accuracy: 0.3827 - val_loss: 1.5328 - val_accuracy: 0.5571\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 53s 991ms/step - loss: 1.9525 - accuracy: 0.3946 - val_loss: 1.4355 - val_accuracy: 0.5381\n",
      "Epoch 16/50\n",
      "22/53 [===========>..................] - ETA: 29s - loss: 1.9001 - accuracy: 0.3866"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(150,150,3),\n",
    "               data_format='channels_last'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(21, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,)\n",
    "\n",
    "model.save(f\"/content/drive/Shareddrives/Data/Model Land Use/model_CNN Acc:{history.history['accuracy'][-1]}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qz5BkhBfjVK"
   },
   "source": [
    "###**7.2 Plot Model Accuracy and Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SktDHoZfhbQ"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(acc, label='Training acc')\n",
    "plt.plot(val_acc, label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZyCF9ejf1KS"
   },
   "source": [
    "###**7.3 Evaluate Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fz78w7mMf7n4"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1u-KnaMf9q0"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [np.argmax(y) for y in y_pred]\n",
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_GaLr3sgC3Z"
   },
   "source": [
    "##**7.4 Plot Confusion Matrix**\n",
    "Plot the confusion matrix to see where the model successfully predicts and fails to predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdtmZwm8gIGq"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    \n",
    "    cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes,rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max()/2.0\n",
    "    \n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        \n",
    "        plt.text(j,i, format(cm[i,j], fmt),\n",
    "                horizontalalignment = \"center\",\n",
    "                color = \"white\" if cm[i,j] > thresh else \"black\")\n",
    "        pass\n",
    "    \n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.grid(None);\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vC-sa5sWgXpa"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [np.argmax(y) for y in y_pred]\n",
    "cnf_mat = confusion_matrix(y_test_class, y_pred_class)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_mat, classes=labels)\n",
    "plt.grid(None)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Utpml5pgcwW"
   },
   "source": [
    "##**8. Transfer Learning with VGG16**\n",
    "###**8.1 Load PreTrained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQDPFYLvgbqg"
   },
   "outputs": [],
   "source": [
    "conv_base = tf.keras.applications.VGG16(weights='imagenet',include_top=False, input_shape=(150, 150, 3))\n",
    "conv_base.trainable = False\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_KPWNTugq1X"
   },
   "source": [
    "###**8.2 Build Model with Pretrained Model as Feature Extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbFX0fFOgpaa"
   },
   "outputs": [],
   "source": [
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "top_model = conv_base.output\n",
    "top_model = tf.keras.layers.Flatten(name=\"flatten\")(top_model)\n",
    "top_model = tf.keras.layers.Dense(4096, activation='relu')(top_model)\n",
    "top_model = tf.keras.layers.Dense(1072, activation='relu')(top_model)\n",
    "top_model = tf.keras.layers.Dropout(0.5)(top_model)\n",
    "output_layer = tf.keras.layers.Dense(21, activation='softmax')(top_model)\n",
    "    \n",
    "# Group the convolutional base and new fully-connected layers into a Model object.\n",
    "model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "# Compiles the model for training.\n",
    "model.compile(optimizer=Adam(learning_rate=2e-5), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=validation_generator)\n",
    "model.save(f\"/content/drive/Shareddrives/Data/Model Land Use/model_VGG Acc:{history.history['accuracy'][-1]}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6Yw3bKyg26o"
   },
   "source": [
    "###**8.3 Plot Model Accuracy and Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpzh5l_Bg1Zi"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(acc, label='Training acc')\n",
    "plt.plot(val_acc, label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BC51518FhI-o"
   },
   "source": [
    "###**8.4  Evaluate Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGVQhVJChF-s"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccIwGYSQhP5p"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [np.argmax(y) for y in y_pred]\n",
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5I76r_ghUj1"
   },
   "source": [
    "###**8.5 Plot Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrFhkdXShSwe"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [np.argmax(y) for y in y_pred]\n",
    "cnf_mat = confusion_matrix(y_test_class, y_pred_class)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_mat, classes=labels)\n",
    "plt.grid(None)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPwVUul0he0K"
   },
   "source": [
    "##**9. Transfer Learning with MobileNet**\n",
    "###**9.1 Build Model with Pretrained Model as Feature Extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqchuE-Jhi-x"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "mobile = MobileNet(weights=\"imagenet\",include_top=False,input_shape=(150,150,3))\n",
    "\n",
    "for layer in mobile.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "top_model = mobile.output\n",
    "top_model = tf.keras.layers.Flatten(name=\"flatten\")(top_model)\n",
    "top_model = tf.keras.layers.Dense(4096, activation='relu')(top_model)\n",
    "top_model = tf.keras.layers.Dense(1072, activation='relu')(top_model)\n",
    "top_model = tf.keras.layers.Dropout(0.5)(top_model)\n",
    "output_layer = tf.keras.layers.Dense(21, activation='softmax')(top_model)\n",
    "    \n",
    "# Group the convolutional base and new fully-connected layers into a Model object.\n",
    "model = Model(inputs=mobile.input, outputs=output_layer)\n",
    "\n",
    "# Compiles the model for training.\n",
    "model.compile(optimizer=Adam(learning_rate=2e-5), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=validation_generator)\n",
    "model.save(f\"/content/drive/Shareddrives/Data/Model Land Use/model_MobileNet Acc:{history.history['accuracy'][-1]}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMAP8ERvh1bU"
   },
   "source": [
    "###**9.2 Plot Model Accuracy and Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTXiXrVmh0R_"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(acc, label='Training acc')\n",
    "plt.plot(val_acc, label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgGwW2WNh7Tu"
   },
   "source": [
    "###**9.3 Evaluate Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rct3Zgdth6Ii"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejMbRa8tiCKP"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [np.argmax(y) for y in y_pred]\n",
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxKhOsXniGrt"
   },
   "source": [
    "###**9.4 Plot Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzlRSKlgiExJ"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [np.argmax(y) for y in y_pred]\n",
    "cnf_mat = confusion_matrix(y_test_class, y_pred_class)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_mat, classes=labels)\n",
    "plt.grid(None)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zLV0KVfiNOB"
   },
   "source": [
    "##**10. Transfer Learning with InceptionV3**\n",
    "###**10.1 Build Model with Pretrained Model as Feature Extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWA3HTPHiLmc"
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "inc = InceptionV3(input_shape=(150, 150, 3),\n",
    "                                    include_top=False)\n",
    "\n",
    "for layer in inc.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "top_model = inc.output\n",
    "top_model = tf.keras.layers.Flatten(name=\"flatten\")(top_model)\n",
    "top_model = tf.keras.layers.Dense(4096, activation='relu')(top_model)\n",
    "top_model = tf.keras.layers.Dense(1072, activation='relu')(top_model)\n",
    "top_model = tf.keras.layers.Dropout(0.5)(top_model)\n",
    "output_layer = tf.keras.layers.Dense(21, activation='softmax')(top_model)\n",
    "    \n",
    "# Group the convolutional base and new fully-connected layers into a Model object.\n",
    "model = Model(inputs=inc.input, outputs=output_layer)\n",
    "\n",
    "# Compiles the model for training.\n",
    "model.compile(optimizer=Adam(learning_rate=2e-5), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=validation_generator)\n",
    "\n",
    "model.save(f\"/content/drive/Shareddrives/Data/Model Land Use/model_Inception Acc:{history.history['accuracy'][-1]}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIGWRD7NimNL"
   },
   "source": [
    "###**10.2 Plot Model Accuracy and Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IG7K6gUYilYG"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(acc, label='Training acc')\n",
    "plt.plot(val_acc, label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQUNdKkFixbU"
   },
   "source": [
    "###**10.3 Evaluate Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Cx57osrivsP"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ke2q1wvFi5JW"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [np.argmax(y) for y in y_pred]\n",
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Eiiv3N1i9ee"
   },
   "source": [
    "###**10.4 Plot Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lXoh2CHi8vZ"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [np.argmax(y) for y in y_pred]\n",
    "cnf_mat = confusion_matrix(y_test_class, y_pred_class)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_mat, classes=labels)\n",
    "plt.grid(None)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPRmteBGjGYS"
   },
   "source": [
    "##**11. Test with random image**\n",
    "###**11.1 Load Model with Best Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qUI3CSFjFv4"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "_path = \"/content/drive/Shareddrives/Data/Model Land Use\"\n",
    "models = os.listdir(_path)\n",
    "best_acc = 0\n",
    "best_model = \"\"\n",
    "\n",
    "regex = r\"(\\d+)(?:\\.(\\d{1,}))\"\n",
    "for _model in models:\n",
    "  acc = re.search(regex,_model)\n",
    "  cur_acc = float(acc.group(0))\n",
    "  if cur_acc > best_acc:\n",
    "    best_acc = cur_acc\n",
    "    best_model = _model\n",
    "\n",
    "model= tf.keras.models.load_model(os.path.join(_path, best_model))\n",
    "print(f\"Model used: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4kZarC8jawS"
   },
   "source": [
    "###**11.2 Upload Image to Test the Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niqQlaAwjZlZ"
   },
   "source": [
    "<!-- from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  img = cv2.imread(fn)\n",
    "  img = cv2.resize(img,(150,150))\n",
    "  img = np.reshape(img,[1,150,150,3])\n",
    "  img_arr = np.zeros((1,150,150,3))\n",
    "  img_arr[0, :, :, :] = img / 255.\n",
    "  y_pred = model.predict(img_arr)\n",
    "  plt.imshow(imread(fn))\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "  print(f\"Predicted as: {class_label[np.argmax(y_pred)]}\") -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
